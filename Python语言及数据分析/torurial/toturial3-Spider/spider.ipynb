{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import jieba\n",
    "\n",
    "from lxml import etree\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Author: Yan Jingcun\n",
    "Date: 2022-04-27\n",
    "Time: 08:10:23\n",
    "Description: 简单爬取贴吧内容\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import requests\n",
    "from lxml import etree\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "\n",
    "# url\n",
    "url = 'https://tieba.baidu.com/f?ie=utf-8&kw=%E9%AC%BC%E8%B0%B7%E5%85%AB%E8%8D%92'\n",
    "\n",
    "# 获取html文档\n",
    "html = requests.get(url)\n",
    "\n",
    "# 可以将从互联网上获取的源码数据加载到该对象中\n",
    "pages = etree.HTML(html.content)\n",
    "\n",
    "# xpath解析\n",
    "# 选取文档中的所有元素, 找到类为 threadlist_title pull_left j_th_tit 的元素\n",
    "# 选取其a标签, 提取a标签中的文本\n",
    "xpath_title = '//*[@class=\"threadlist_title pull_left j_th_tit \"]/a/text()'\n",
    "xpath_time = '//*[@class=\"threadlist_reply_date pull_right j_reply_data\"]/text()'\n",
    "xpath_author = '//*[@class=\"frs-author-name j_user_card \"]/text()'\n",
    "\n",
    "\n",
    "# 使用xpath解析出标题\n",
    "titles = pages.xpath(xpath_title)\n",
    "times = pages.xpath(xpath_time)\n",
    "authors = pages.xpath(xpath_author)\n",
    "\n",
    "# 写入文档\n",
    "i = 1\n",
    "with open('titles.txt', 'w') as f:\n",
    "  f.write('序号\\t标题\\t作者\\t最后回复时间')\n",
    "  for line, time, author in zip(titles, times, authors):\n",
    "    f.write(str(i) + '\\t' + line + '\\t' + author + '\\t' + time.strip() + '\\n')\n",
    "    i += 1\n",
    "\n",
    "f.close()\n",
    "\n",
    "print('SUCCESS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 微信公众号文章爬取\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -!- coding: utf-8 -!-\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "\n",
    "#加载chromedriver\n",
    "driver = webdriver.Firefox(executable_path='./utils/geckodriver.exe', firefox_binary='U://FireFox/Firefox/firefox.exe')\n",
    "#进入主页\n",
    "url = 'http://weixin.sogou.com/'\n",
    "driver.get(url)\n",
    "#输入搜索内容\n",
    "#Input = driver.find_element_by_xpath('//*[@id=\"query\"]')\n",
    "input = driver.find_element(By.XPATH,'//*[@id=\"query\"]')\n",
    "input.send_keys('三体')\n",
    "#点击“搜文章”按钮\n",
    "#button = driver.find_element_by_xpath('//*[@id=\"searchForm\"]/div/input[3]')\n",
    "button = driver.find_element(By.XPATH, '//*[@id=\"searchForm\"]/div/input[3]')\n",
    "button.click()\n",
    "#点击“搜索工具”按钮，显示高级搜素内容\n",
    "#search = driver.find_element_by_xpath('//*[@id=\"tool_show\"]/a')\n",
    "search = driver.find_element(By.XPATH, '//*[@id=\"tool_show\"]/a')\n",
    "search.click()\n",
    "#点击“全部时间”按钮，打开时间筛选框\n",
    "#time = driver.find_element_by_xpath('//*[@id=\"time\"]')\n",
    "time = driver.find_element(By.XPATH, '//*[@id=\"time\"]')\n",
    "time.click()\n",
    "#清空开始吋间，并输入开始时间\n",
    "start_time = driver.find_element(By.XPATH, '//*[@id=\"date_start\"]')\n",
    "start_time.clear()\n",
    "start_time.send_keys('2021-06-01')\n",
    "#清空结朿时间，并输入结束时间\n",
    "end_time = driver.find_element(By.XPATH, '//*[@id=\"date_end\"]')\n",
    "end_time.clear()\n",
    "end_time.send_keys('2021-07-01')\n",
    "#点击确定按钮\n",
    "ok=driver.find_element(By.XPATH, '//*[@id=\"time_enter\"]')\n",
    "ok.click()\n",
    "# link_list用于保存每个文章的url链接\n",
    "link_list = list()\n",
    "#遍历前10页的内容\n",
    "for page in range(10):\n",
    "#每一页有10篇文章\n",
    "   for i in range(0, 9):\n",
    "      try:\n",
    "         #动态生成文章题目的xpath\n",
    "         id ='//*[@id=\"sogou_vr_11002601_title_'+str(i)+ ' \"]'\n",
    "         # 使用get_attribute ()方法获取href属性值\n",
    "         title = driver.find_element(By.XPATH, id).get_attribute('href')\n",
    "         print(title)\n",
    "         #把获取到的链接保存到link_list中去\n",
    "         link_list.append(title)\n",
    "      except:\n",
    "         continue\n",
    "#使用“下一页”按钮进行翻页\n",
    "         next=driver.find_element(By.XPATH, '//*[@id=\"sogou_next\"]')\n",
    "      next.click()\n",
    "#打开文件result2.txt，把获取的内容写入其中\n",
    "with open('result2.txt', 'w', encoding='utf-8') as result:\n",
    "    for link in link_list:\n",
    "        try:\n",
    "            #打开文章页面\n",
    "            driver.get(link)\n",
    "            #获取元素的文本内容，使用.text来获取\n",
    "            title = driver.find_element(By.XPATH, '//*[@id=\"activity-name\"]').text\n",
    "            id = driver.find_element(By.XPATH, '//*[@id=\"post-user\"]').text\n",
    "            date = driver.find_element(By.XPATH, '//*[@id=\"post-date\"]').text\n",
    "            content = driver.find_element(By.XPATH, '//*[@id=\"js_content\"]').text\n",
    "            msg = date + '\\t' + id+'\\t' + title + '\\n' +content + '\\n' + '---'*60\n",
    "            print(msg)\n",
    "            #写入文件\n",
    "            result.write(msg+'\\n')\n",
    "        except:\n",
    "            continue\n",
    "#关闭chromedriver\n",
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 豆瓣评论爬取及词云展示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据爬取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Yan Jingcun\n",
    "Date: 2022-05-02\n",
    "Time: 10:57:48\n",
    "Description: 爬取数据并保存\n",
    "\"\"\"\n",
    "\n",
    "from lxml import etree\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from time import sleep\n",
    "\n",
    "bro = webdriver.Firefox(executable_path='./utils/geckodriver.exe', firefox_binary='U://FireFox/Firefox/firefox.exe')\n",
    "\n",
    "url = 'https://book.douban.com/subject/5363767/reviews?start=20'\n",
    "\n",
    "bro.get(url)\n",
    "list_elements = bro.find_elements(by=By.CLASS_NAME, value=\"unfold\")\n",
    "\n",
    "# 这个页面一共的元素\n",
    "element_number = len(list_elements)\n",
    "\n",
    "with open('content2.txt', 'w+', encoding='utf-8') as f:\n",
    "\n",
    "  # 打开每一个节点, 中间显式等待\n",
    "  for i in range(element_number):\n",
    "    list_elements = bro.find_elements(by=By.CLASS_NAME, value=\"unfold\")[i].click()\n",
    "    sleep(2)\n",
    "    # 点击展开之后查找目标元素\n",
    "    xpath = '//*[@class=\"review-content clearfix\"]/text()'\n",
    "    page_text = bro.page_source\n",
    "    tree = etree.HTML(page_text)\n",
    "    text = tree.xpath(xpath)\n",
    "    for content in text:\n",
    "      f.write(content)\n",
    "    # 刷新页面\n",
    "    bro.refresh()\n",
    "\n",
    "bro.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 词云展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x2037aa2feb0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import jieba\n",
    "import re\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "#注意到获取的页面内容中有html的标签和其他符号存在，不利于下一步的词云操作，所以需要利用jieba和正则表达式对得到的文本进行清洗\n",
    "r ='[，。\\%、；1234567890n-】【“”]'\n",
    "\n",
    "file=open(\"./content.txt\",\"r\",encoding='utf-8').read()\n",
    "\n",
    "#剔除无关信息\n",
    "file =re.sub(r,'',file)      \n",
    "chinese_char = '[你我他她它和就是了都也这我们被一只那中个上与又所能到不还说可以很而但对为的在什么没有]'\n",
    "file = re.sub(chinese_char,'',file)\n",
    "\n",
    "#分词\n",
    "con = jieba.lcut(file)     \n",
    "\n",
    "#分词后插入空格\n",
    "words = \" \".join(con)    \n",
    "\n",
    "#词云分析\n",
    "wordcloud = WordCloud(font_path=\"simkai.ttf\",background_color=\"white\",width=1300, height=800).generate(words)\n",
    "\n",
    "wordcloud.to_file('cloud.png')     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "58d3b07a0f44d67ebabf5741bf33bff5b7095a9965bbbcb16e115a1bfd5f21ab"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
